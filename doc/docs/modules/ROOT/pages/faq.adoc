
[[faq]]
= Neo4j Streams FAQ

== Source Code License

The source code to Neo4j Streams is available under the terms of the Apache License, version 2.0.  See the LICENSE file in
the source code repository for full terms and conditions.

== How to integrate Neo4j and Kafka

When integrating Neo4j and Kafka using Neo4j Streams plugin or Kafka Connect Neo4j Connector
is important configure just one of them and not both.

== About CUD file format

The CUD file format is JSON file that represents Graph Entities (Nodes/Relationships) and how to manage them in term
of **C**reate/**U**pdate/**D**elete operations.
So every JSON event represents a single operation.
For more details about how to use these, please checkout the xref:kafka-connect.adoc#kafka-connect-cud-file-format[CUD File Format] section for Kafka Connect Neo4j Connector.

== Is Neo4j Streams supported by Confluent Cloud?

If the need is to run the connector as a managed service then the answer is no.
Users who are interested in running Neo4j-Streams as a Cloud managed connector by Confluent should request this of Confluent.
Right now there are only a few connectors such as that for S3 that can be run as managed services.
Click {url-confluent-cloud}/connectors/index.html[here] to learn more.

Other references to how to configure it to connect to the Confluent Cloud can be found at the following links:

* {url-confluent-blog}/kafka-graph-visualizations/ (see the `Configuring Neo4j to interact with Kafka` section).

* https://github.com/neo4j-contrib/neo4j-streams/issues/182

== How to configure Kafka over SSL?

Checkout also the Confluent Kafka official documentation for further details on this topic.
Here are some helpful links:

* https://docs.confluent.io/current/security/security_tutorial.html[Security Tutorial]

* {url-confluent-kafka}/encryption.html[Encryption with SSL]

* {url-confluent-kafka}/authentication_sasl/index.html[Authentication with SASL]

* https://docs.confluent.io/platform/current/connect/security.html[Kafka Connect Security]

== Kafka cluster and topic with multiple partition setup

If the environment is a Kafka cluster composed by:

--
* multiple Zookeepers servers
* multiple Kafka brokers
* topics with multiple partitions
* a Neo4j instance configured as Sink
--

is important to setup Zookeeper servers correctly.
This means that the number of Zookeeper instances has to be `2n+1` where `n` is any number greater then 0.
This because the odd number of servers allows ZooKeeper to perform majority elections for leadership.

So, if the cluster is not setup properly, what could happens is that events produced in some partitions may not
be read.

Please see the following link for further details:

--
* https://www.oreilly.com/library/view/kafka-the-definitive/9781491936153/ch04.html[Kakfa Consumer and Consumer Groups concepts]
* https://docs.confluent.io/platform/current/kafka/deployment.html#multi-node-configuration[Kafka multi-node configuration]
* https://docs.confluent.io/platform/current/zookeeper/deployment.html#multi-node-setup[Zookeeper multi-node setup]
--

== Which way should I run the Neo4j Connector for Apache Kafka: As a database plugin, or using the Kafka Connect Framework?

If you have already implemented the database plugin and are running Neo4j <= 4.2, there is no need to change, all other users, new users, and Neo4j Aura users should implement only the Kafka Connect Neo4j Connector
